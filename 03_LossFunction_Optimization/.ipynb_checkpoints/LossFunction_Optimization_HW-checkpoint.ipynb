{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import math\n",
    "\n",
    "import random\n",
    "from sklearn.datasets.samples_generator import make_regression\n",
    "import pylab\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "# from sklearn.datasets import make_blobs\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = make_regression(n_samples=100, n_features=1, n_informative=1, random_state=20, noise=40)\n",
    "\n",
    "a = x\n",
    "b = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(x,y,'o')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n = np.shape(x)\n",
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -1.62950152],\n",
       "       [ 1.        ,  1.        , -0.51314511],\n",
       "       [ 1.        ,  1.        , -1.41666675],\n",
       "       [ 1.        ,  1.        ,  1.56763255],\n",
       "       [ 1.        ,  1.        ,  0.55427493]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.c_[np.ones(m), x]\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.58259451 96.20840738]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "m = x.shape[0]\n",
    "# theta = np.random.randn(2,1)\n",
    "theta =[-1,-1]\n",
    "\n",
    "x_transpose = x.transpose()\n",
    "# x_transpose\n",
    "for iter in range (0,100):\n",
    "    hypothesis = np.dot(x,theta)\n",
    "    \n",
    "    loss = hypothesis - y\n",
    "    J = np.sum(loss ** 2) / (2 * n)\n",
    "#     print(\"iter %s| J: %.3f\" % (iter, J))\n",
    "#     print(theta)\n",
    "    \n",
    "    gradient = np.dot(x_transpose, loss)\n",
    "    theta = theta - alpha * gradient\n",
    "    \n",
    "print(theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = -3\n",
    "x2 = 3\n",
    "y1 = theta[0] + theta[1] * x1\n",
    "y2 = theta[0] + theta[1] * x2\n",
    "\n",
    "point1 = [x1, y1]\n",
    "point2 = [x2, y2]\n",
    "\n",
    "x_values = [point1[0], point2[0]]\n",
    "y_values = [point1[1], point2[1]]\n",
    "\n",
    "\n",
    "pylab.plot(a,b,'o')\n",
    "pylab.plot(x_values,y_values)\n",
    "# pylab.plot(x2,y2,'x')\n",
    "pylab.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_y = data.target[50:]\n",
    "sel_y\n",
    "i = 0\n",
    "for i in range(len(sel_y)):\n",
    "    if sel_y[i] == 1:\n",
    "        sel_y[i] = 0\n",
    "    else:\n",
    "        sel_y[i] = 1\n",
    "len(sel_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-28cc97cff638>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msel_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vec' is not defined"
     ]
    }
   ],
   "source": [
    "sel_x = data.data[50:]\n",
    "\n",
    "X = vec.fit_transform(sel_x)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [100, 150]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-249e4a05ea01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msel_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# data = sns.load_dataset(\"iris\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# data.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2141\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2143\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m         \"\"\"\n\u001b[1;32m-> 1328\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [100, 150]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sel_x, sel_y, test_size=0.30, random_state = 2020, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  spec\n",
       "50            7.0          3.2           4.7          1.4     0\n",
       "51            6.4          3.2           4.5          1.5     0\n",
       "52            6.9          3.1           4.9          1.5     0\n",
       "53            5.5          2.3           4.0          1.3     0\n",
       "54            6.5          2.8           4.6          1.5     0\n",
       "..            ...          ...           ...          ...   ...\n",
       "145           6.7          3.0           5.2          2.3     1\n",
       "146           6.3          2.5           5.0          1.9     1\n",
       "147           6.5          3.0           5.2          2.0     1\n",
       "148           6.2          3.4           5.4          2.3     1\n",
       "149           5.9          3.0           5.1          1.8     1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sns.load_dataset(\"iris\")\n",
    "data.head(51)\n",
    "\n",
    "iris_data = data.drop(data[(data.species == 'setosa')].index)\n",
    "\n",
    "\n",
    "def get_species(row):\n",
    "    if row['species'] == 'versicolor':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "iris_data['spec'] = data.apply(get_species, axis=1)\n",
    "iris_data.drop(['species'], axis=1, inplace=True)\n",
    "iris_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_data.iloc[:, :-1]\n",
    "y = iris_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train) #Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "133           6.3          2.8           5.1          1.5\n",
       "103           6.3          2.9           5.6          1.8\n",
       "120           6.9          3.2           5.7          2.3\n",
       "95            5.7          3.0           4.2          1.2\n",
       "94            5.6          2.7           4.2          1.3\n",
       "89            5.5          2.5           4.0          1.3\n",
       "72            6.3          2.5           4.9          1.5\n",
       "130           7.4          2.8           6.1          1.9\n",
       "60            5.0          2.0           3.5          1.0\n",
       "50            7.0          3.2           4.7          1.4\n",
       "68            6.2          2.2           4.5          1.5\n",
       "80            5.5          2.4           3.8          1.1\n",
       "123           6.3          2.7           4.9          1.8\n",
       "83            6.0          2.7           5.1          1.6\n",
       "140           6.7          3.1           5.6          2.4\n",
       "54            6.5          2.8           4.6          1.5\n",
       "126           6.2          2.8           4.8          1.8\n",
       "127           6.1          3.0           4.9          1.8\n",
       "62            6.0          2.2           4.0          1.0\n",
       "81            5.5          2.4           3.7          1.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.94      0.96      0.95        20\n",
      "weighted avg       0.96      0.95      0.95        20\n",
      "\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Test the model\n",
    "predictions = model.predict(x_test)\n",
    "print(predictions)# printing predictions\n",
    "\n",
    "print()# Printing new line\n",
    "\n",
    "#Check precision, recall, f1-score\n",
    "print( classification_report(y_test, predictions) )\n",
    "\n",
    "print( accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35674468, -0.73750193,  2.83425127,  2.19287166]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_ex = np.c_[7.0, 3.2,4.7,1.4]\n",
    "theta_log = np.c_[-0.35674468, -0.73750193,  2.83425127,  2.19287166]\n",
    "# iris_ex = np.c_[X]\n",
    "iris_ex = iris_ex.transpose()\n",
    "# theta_log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999966007982917"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hypoth = 7.0 * (-0.35674468) + 3.2 * (-0.73750193) + 4.7 * (2.83425127) + 1.4 * (2.19287166)\n",
    "# hypoth = 5.9 * (-0.35674468) + 3.0 * (-0.73750193) + 5.1 * (2.83425127) + 1.8 * (2.19287166)\n",
    "# 5.7\t3.0\t4.2\t1.2\n",
    "\n",
    "hypoth = 5.7 * (-0.35674468) + 3.0 * (-0.73750193) + 4.2 * (2.83425127) + 1.2 * (2.19287166)\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "# hypoth = 1.0 / (1 + np.exp(np.dot(iris_ex,theta_log)))\n",
    "# 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "res = 1.0 / (1 + np.exp(-1 * hypoth))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x_data, y_data, learning_rate,iterations,parameters): \n",
    "    size = x_data.shape[0]\n",
    "    weight = parameters[\"weight\"] \n",
    "    bias = parameters[\"bias\"]\n",
    "    \n",
    "\n",
    "    for i in range(iterations): \n",
    "        prediction = 1 / (1 + np.exp(-(np.dot(x_data, weight) + bias)))\n",
    "        loss = -1/size * np.sum(y_data * np.log(prediction)) + (1 - y_data) * np.log(1-prediction)\n",
    "        \n",
    "        dW = 1/size * np.dot(x_data.T, (prediction - y_data))\n",
    "        db = 1/size * np.sum(prediction - y_data)\n",
    "        \n",
    "        weight -= learning_rate * dW\n",
    "        bias -= learning_rate * db\n",
    "    \n",
    "    parameters[\"weight\"] = weight\n",
    "    parameters[\"bias\"] = bias\n",
    "    return parameters\n",
    "\n",
    "init_parameters = {} \n",
    "init_parameters[\"weight\"] = np.zeros(x_train.shape[1])\n",
    "init_parameters[\"bias\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': array([-0.14874384, -0.14194362,  0.26453855,  0.20828173]),\n",
       " 'bias': -0.07178986629776962}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(x_data, y_data, learning_rate,iterations):\n",
    "    parameters_out = optimize(x_data, y_data, learning_rate, iterations ,init_parameters)\n",
    "    return parameters_out\n",
    "\n",
    "parameters_out = train(x_train, y_train, learning_rate = 0.01, iterations = 100)\n",
    "parameters_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5863373065904796"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hypoth = 5.7 * (-0.66136248) + 3.0 * (-0.61724089) + 4.2 * (1.0203255) + 1.2 * (0.84424634) + -0.312020\n",
    "\n",
    "# hypoth = 7.0 * (-0.66136248) + 3.2 * (-0.61724089) + 4.7 * (1.0203255) + 1.4 * (0.84424634) + -0.312020\n",
    "\n",
    "w = parameters_out[\"weight\"]\n",
    "b = parameters_out[\"bias\"]\n",
    "\n",
    "# hypoth = 7.0 * w[0] + 3.2 * w[1] + 4.7 * w[2] + 1.4 * w[3] + b\n",
    "\n",
    "hypoth = 5.9 * w[0] + 3.0 * w[1] + 5.1 * w[2] + 1.8 * w[3] + b\n",
    "\n",
    "\n",
    "# 5.9\t3.0\t5.1\t1.8\n",
    "\n",
    "\n",
    "res = 1.0 / (1 + np.exp(-1 * hypoth))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(x_data, y_data, learning_rate,iterations,parameters): \n",
    "    size = x_data.shape[0]\n",
    "    weight = parameters[\"weight\"] \n",
    "    bias = parameters[\"bias\"]\n",
    "    \n",
    "    prev_v_w = 0.0\n",
    "    prev_v_b = 0.0\n",
    "    \n",
    "    v_t = 0.0\n",
    "    \n",
    "    gamma = 0.9\n",
    "    \n",
    "\n",
    "    for i in range(iterations): \n",
    "        \n",
    "        w_star = weight - learning_rate * prev_v_w\n",
    "        b_star = bias - learning_rate * prev_v_b\n",
    "        \n",
    "        prediction = sigmoid(np.dot(x_data, w_star) + b_star)\n",
    "        loss = -1/size * np.sum(y_data * np.log(prediction)) + (1 - y_data) * np.log(1-prediction)\n",
    "        \n",
    "        \n",
    "        \n",
    "        dW = 1/size * np.dot(x_data.T, (prediction - y_data))\n",
    "        db = 1/size * np.sum(prediction - y_data)\n",
    "        \n",
    "        weight -= learning_rate * dW\n",
    "        bias -= learning_rate * db\n",
    "    \n",
    "        prev_v_w = weight\n",
    "        prev_v_b = bias\n",
    "    \n",
    "    \n",
    "    parameters[\"weight\"] = weight\n",
    "    parameters[\"bias\"] = bias\n",
    "    return parameters\n",
    "\n",
    "init_parameters = {} \n",
    "init_parameters[\"weight\"] = np.zeros(x_train.shape[1])\n",
    "init_parameters[\"bias\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
